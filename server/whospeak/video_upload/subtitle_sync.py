# ë¼ì´ë¸ŒëŸ¬ë¦¬ import
from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip
from moviepy.video.tools.subtitles import SubtitlesClip
from googletrans import Translator
from langdetect import detect
import codecs
import pickle
import argparse
import os
import json
import time

from moviepy.config import change_settings
change_settings({"IMAGEMAGICK_BINARY": r"C:\Program Files\ImageMagick-7.1.1-Q16-HDRI\\magick.exe"})

translator = Translator()

print("=" * 50)
print()
print('subtitle_sync ì‹¤í–‰ ì¤‘...')
startT = time.time()

# argparseë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì˜ìƒ íŒŒì¼ ì´ë¦„ì„ ì…ë ¥ìœ¼ë¡œ ë°›ìŒ
parser = argparse.ArgumentParser(description = "video Name")
parser.add_argument('--videoName', type=str, default='001')    # ë¹„ë””ì˜¤ ì´ë¦„
parser.add_argument('--language', type=str, default='ko')     # íƒ€ê²Ÿ ì–¸ì–´
args = parser.parse_args()
file_nm = args.videoName.split('.')[0]

# ìë§‰ íŒŒì¼ ê²½ë¡œ
srt_path = os.path.join(os.pardir, 'media', 'srt', f'{file_nm}.srt')
# ë™ì˜ìƒ íŒŒì¼ ê²½ë¡œ
video_path = os.path.join(os.pardir, 'media', 'videos', file_nm , 'pyavi', 'video_out.avi')
# ë™ì˜ìƒ ë¡œë“œ
video = VideoFileClip(video_path)
# ì›í•˜ëŠ” ì¶”ì¶œ ì–¸ì–´
output_lang = args.language
# ì–¼êµ´ pickle íŒŒì¼
face_score = os.path.join(os.pardir, 'media', 'videos', file_nm , 'pywork', 'scoring.pckl')

# pickle íŒŒì¼ ì½ê¸°
with open(face_score, 'rb') as f:
    faces_score = pickle.load(f)

# srt íŒŒì¼ ì½ê¸°
try:
    with codecs.open(srt_path, 'r', 'utf-8') as file:
        lines = file.readlines()
except:
    with codecs.open(srt_path, 'r', 'cp949') as file:
        lines = file.readlines()

# srtíŒŒì¼ì˜ ì‹œê°„ì„ ì´ˆë‹¨ìœ„ë¡œ ë³€ê²½í•˜ëŠ” í•¨ìˆ˜
def time_to_seconds(time_str):
    h, m, s = map(float, time_str.split(':'))
    seconds = h * 3600 + m * 60 + s
    return seconds

# ë²ˆì—­í•¨ìˆ˜
def translate(text, target='ko'):
    # do not translate if text is Korean.
    if detect(text) == target:
        return text

    try:
        result = translator.translate(text, str(target)).text
    except Exception as e:
        print(f"Translation error: {e}")
        result = text
    return result

# ìë§‰ì´ í™”ë©´ ë°–ìœ¼ë¡œ ë‚˜ê°€ëŠ” ê²ƒì„ ë°©ì§€í•˜ëŠ” í•¨ìˆ˜
def prevent_out(x, y, video, subtitles_clip):
    xx = min(max(0.02*video.w, x), 0.98*video.w - subtitles_clip.w)
    yy = min(max(0.02*video.h, y), 0.98*video.h - subtitles_clip.h)
    return xx, yy


# ìë§‰ì´ ë°°ì¹˜ëœ ë¦¬ìŠ¤íŠ¸
subtitles_clip = []
# í™”ì ê¸°ì¤€ ìë§‰ ë°°ì¹˜ ìœ„ì¹˜ ë¦¬ìŠ¤íŠ¸
po_loc = []
point_loc = []
# í™”ì tracking ë¦¬ìŠ¤íŠ¸
po_tra = []
# ì¶”ì¶œí•  pickle íŒŒì¼
out_pickle = []


k = 2
while k < len(lines):
    # ë‘ëª…ì˜ í™”ìê°€ ë§í• ë•Œ
    if lines[k+2][:2] == '--':
        line_2 = lines[k+2].replace('-','').strip() +'\n' + lines[k+3].replace('-','').strip()
        # srtíŒŒì¼ì—ì„œ ìë§‰ì˜ ì‹œì‘ì‹œê°„ê³¼ ë ì‹œê°„ì„ ë½‘ì•„ì£¼ëŠ” í•¨ìˆ˜
        start_time, end_time = lines[k + 1].strip().replace('\r','').split(' --> ')
        text = line_2.strip()
        k+=5
        #print('ddddddddd')
        
    else:
        # srtíŒŒì¼ì—ì„œ ìë§‰ì˜ ì‹œì‘ì‹œê°„ê³¼ ë ì‹œê°„ì„ ë½‘ì•„ì£¼ëŠ” í•¨ìˆ˜
        #print(k)
        start_time, end_time = lines[k + 1].strip().replace('\r','').split(' --> ')
        text = lines[k + 2].strip()
        k+=4
        # print(text)
    
    # ìë§‰ ìƒì„± ì•ˆë˜ì—ˆì„ ê²½ìš° ì—ëŸ¬ ë°©ì§€
    if text == '':
        continue
        
    # ì›í•˜ëŠ” ì–¸ì–´ë¡œ ìë§‰ ë²ˆì—­
    text = translate(text, str(output_lang))
    
    # ìë§‰ ê¸¸ë©´ ì¤„ë°”ê¿ˆ
    if len(text) > 30:
        for i in range(30, 0, -1):
            if text[i] == ' ':
                text = text[:i]+'\n'+text[i+1:]
                break
    
    # ìë§‰ì„ ë°°ì¹˜
    if output_lang == 'ko':
        font = 'Malgun-Gothic'
    else:
        font = 'Arial-Unicode-MS'

    text_clip = (
        TextClip(text, fontsize=24, color='white', font=font)
        .set_position(("center", "bottom"))
        .set_start(start_time)
        .set_end(end_time)
    )
    
    start = int(time_to_seconds(start_time.replace(',','.'))*video.fps) # ì´ˆ * í”„ë ˆì„ (ex: 3ì´ˆë¶€ë¶„ , 25 í”„ë ˆì„ => 75)
    end = int(time_to_seconds(end_time.replace(',','.'))*video.fps)
    # ìë§‰ì´ ë‚˜ì˜¤ëŠ” ì¤‘ê°„ ì‹œê°„ ê¸°ì¤€
    mid = int((start+end)//2)
    # score ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    top_face = sorted(faces_score[mid], key=lambda x: x['score'], reverse=True)
    
    loc = True
     
    # print(0.5*video.w - 0.5*text_clip.w)    
    # ìë§‰ì˜ ì¤‘ê°„ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ” bounding boxê°€ ì—†ì„ë•Œ ì•„ë˜ìª½ì— ìë§‰ ë°°ì¹˜
    if [d['bbox'] for d in top_face] == []:
        text_clip = text_clip.set_position((0.5*video.w - 0.5*text_clip.w, 0.95*video.h - text_clip.h))
        point_loc.append((0.5*video.w - 0.5*text_clip.w, 0.95*video.h - text_clip.h))
        
    # scoreê°€ 0ë³´ë‹¤ ì‘ìœ¼ë©´ í™”ìê°€ ì—†ìœ¼ë¯€ë¡œ ì•„ë˜ìª½ì— ìë§‰ ë°°ì¹˜
    elif float(top_face[0]['score']) < 0:
        text_clip = text_clip.set_position((0.5*video.w - 0.5*text_clip.w, 0.95*video.h - text_clip.h))
        point_loc.append((0.5*video.w - 0.5*text_clip.w, 0.95*video.h - text_clip.h))

    else:
        # scoreê°€ ê°€ì¥ í° bounding boxì˜ 1.6ë°° í° boxì˜ ì™¼ìª½ ì•„ë˜ ëª¨ì„œë¦¬ë¶€ë¶„ì— ìë§‰ë°°ì¹˜
        xx1, yy1, xx2, yy2 = [d['bbox'] for d in top_face][0]
        x1 = xx1 - 0.3*abs(xx2 - xx1)
        y1 = yy1 - 0.3*abs(yy2 - yy1)
        x2 = xx2 + 0.3*abs(xx2 - xx1)
        y2 = yy2 + 0.3*abs(yy2 - yy1)
        x = min(max(0.02*video.w, x1), 0.98*video.w - text_clip.w)
        y = min(max(0.02*video.h, y2), 0.98*video.h - text_clip.h)
        # ìë§‰ì´ í™”ë©´ ë°–ìœ¼ë¡œ ë‚˜ê°€ëŠ” ê²ƒì„ ë°©ì§€
        text_clip = text_clip.set_position([x, y])
        
        loc = False
            
        if len([d['bbox'] for d in top_face]) == 1:
            point_loc.append((x, y))
            pass
        
        # bboxê°€ ì—¬ëŸ¬ê°œì¼ë•Œ
        else:
            sub_change = False
            # ë§Œë“¤ì–´ì§„ ìë§‰ì´ ë‹¤ë¥¸ bboxì— ê²¹ì¹ ë•Œ
            for x_1, y_1, x_2, y_2 in [d['bbox'] for d in top_face][1:]:
                if ((min(max(x_1, x), x_2) == x) or (min(max(x_1, x+text_clip.w), x_2) == x+text_clip.w)) and ((min(max(y_1, y), y_2) == y) or (min(max(y_1, y+text_clip.h), y_2) == y+text_clip.h)):
                    sub_change = True
                    print(x_1, y_1, x_2, y_2)
                    
            if sub_change == False:
                point_loc.append((x, y))
                
            # ë§Œë“¤ì–´ì§„ ìë§‰ì´ ë‹¤ë¥¸ bboxì— ê²¹ì¹ ë•Œ
            else:
                print(x,y, x+text_clip.w, y+text_clip.h)
                # ìë§‰ì˜ í›„ë³´ ìœ„ì¹˜ ì„ ì •
                x3, y3 = x1, y1 - text_clip.h
                x4, y4 = x2, y1 - text_clip.h
                x5, y5 = x1 - text_clip.w, y1
                x6, y6 = x2, y1
                x7, y7 = x2, y2
                
                # ìë§‰ì˜ í›„ë³´ ìœ„ì¹˜ ë¦¬ìŠ¤íŠ¸
                plist = [(x3,y3),(x4,y4),(x5,y5),(x6,y6),(x7,y7)]
                
                # ìë§‰ í›„ë³´ ìœ„ì¹˜ ë¦¬ìŠ¤íŠ¸ì— ìë§‰ ë°©ì§€ ì ìš©
                plist_p = []
                for xx_1, yy_1 in plist:
                    plist_p.append(prevent_out(xx_1, yy_1, video, text_clip))
                
                # ê° í›„ë³´ì— ìë§‰ì´ ìƒì„±ë˜ì—ˆì„ ë•Œ bboxì— ê²¹ì¹˜ëŠ” ì§€ ë¦¬ìŠ¤íŠ¸
                sub_change2 = [False, False, False, False, False]
                
                # ê²¹ì¹˜ë©´ Trueë¡œ ë³€ê²½
                for i in range(5):
                    for x_1, y_1, x_2, y_2 in [d['bbox'] for d in top_face][1:]:
                        if (
                            (min(max(x_1, plist_p[i][0]), x_2) == plist_p[i][0])\
                        or (min(max(x_1, plist_p[i][0]+text_clip.w), x_2) == plist_p[i][0]+text_clip.w))\
                        and ((min(max(y_1, plist_p[i][1]), y_2) == plist_p[i][1])\
                        or (min(max(y_1, plist_p[i][1]+text_clip.h), y_2) == plist_p[i][1]+text_clip.h)):
                            sub_change2[i] = True
                            
                print(sub_change2)
                
                # ìë§‰ì˜ ê° í›„ë³´ì¤‘ì— bboxì— ê²¹ì¹˜ì§€ ì•ŠëŠ” í›„ë³´ì˜ ì¤‘ì  ë¦¬ìŠ¤íŠ¸ ìƒì„±
                pointmid_lst = []
                for num, (x, y) in enumerate(plist_p):
                    if sub_change2[num] == True:
                        pointmid_lst.append((True, True))
                    else:
                        pointmid_lst.append(((2*x+text_clip.w)/2, (2*y+text_clip.h)))
                # print(pointmid_lst)
                
                # ìë§‰ì˜ ê° í›„ë³´ì˜ ì¤‘ì ì—ì„œ bboxì˜ ì¤‘ì ë¦¬ìŠ¤íŠ¸ ì‚¬ì´ì˜ ê±°ë¦¬ í•© ë¦¬ìŠ¤íŠ¸ ìƒì„±
                dis_lst = []
                for num, (x, y) in enumerate(pointmid_lst):
                    dis = 0
                    if pointmid_lst[num] == (True, True):
                        dis_lst.append(0)
                    else:
                        for x_1, y_1, x_2, y_2 in [d['bbox'] for d in top_face][1:]:
                            bx_mid = (x_1+x_2)/2
                            by_mid = (y_1+y_2)/2
                            dis += ((x - bx_mid)**2 + (y - by_mid)**2)**0.5
                        dis_lst.append(dis)
                
                # ê±°ë¦¬ í•©ì´ ê°€ì¥ í° í›„ë³´ ì°¾ê¸°
                loc = 0
                for i in dis_lst:
                    if i == max(dis_lst):
                        break
                    loc += 1
                
                print(text)
                # ê·¸ í›„ë³´ì— ìë§‰ ë°°ì¹˜
                text_clip = text_clip.set_position([plist_p[loc][0], plist_p[loc][1]])
                
                # ëª¨ë“  í›„ë³´ì— bboxê°€ ê²¹ì¹  ê²½ìš° ì•„ë˜ì— ìë§‰ ë°°ì¹˜        
                if sub_change2 == [True, True, True, True, True]:
                    text_clip = text_clip.set_position((0.5*video.w - 0.5*text_clip.w, 0.95*video.h - text_clip.h))
                    point_loc.append((0.5*video.w - 0.5*text_clip.w, 0.95*video.h - text_clip.h))
                else:
                    # x1, y2 ê°’ì„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                    point_loc.append((plist_p[loc][0], plist_p[loc][1]))
        
        # ì´ì „ ìë§‰ê³¼ í˜„ì¬ ìë§‰ì˜ í™”ìê°€ ê°™ì€ë° ìë§‰ í›„ë³´ì˜ ìœ„ì¹˜ê°€ ë‹¤ë¥¸ ê²½ìš° í˜„ì¬ ìë§‰ í›„ë³´ ìœ„ì¹˜ë¡œ ì´ì „ ìë§‰ í›„ë³´ì˜ ìœ„ì¹˜ë¥¼ ë³€ê²½
        for i in range(len(po_loc)-1, -1, -1):
            if (po_loc[i] != loc) and (po_tra[i] == [d['track'] for d in top_face][0]):
                subtitles_clip[i] = subtitles_clip[i].set_position(point_loc[i+1]) # ë°”ê¾¼ë¶€ë¶„
                point_loc[i] = point_loc[i+1] # ë°”ê¾¼ë¶€ë¶„
            else:
                break
    
    # trackingì„ í†µí•´ ìë§‰ì˜ í™”ìê°€ ëˆ„êµ°ì§€ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
    if [d['track'] for d in top_face] == []:
        po_tra.append(None)
    else:
        po_tra.append([d['track'] for d in top_face][0])
    po_loc.append(loc)
    

    #print('--------------')
    out_pickle.append({'start_frame': start, 'end_frame': end, 'pos': point_loc[-1], 'text': text, 'start_time': start_time, 'end_time': end_time})
    subtitles_clip.append(text_clip)


output_path = os.path.join(os.pardir, 'media', 'mid_json', f'{file_nm}.json')

with open(output_path, 'w') as f:
    out_json = { 'data' : out_pickle }
    json.dump(out_json, f, indent = 4)

endT = time.time()

print()
print('subtitle_sync ì‹¤í–‰ ì™„ë£Œ')
print(f"ğŸ•’ê±¸ë¦° ì‹œê°„ : {endT - startT:.2f} sec")
print()