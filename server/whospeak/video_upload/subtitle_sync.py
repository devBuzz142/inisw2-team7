# ë¼ì´ë¸ŒëŸ¬ë¦¬ import
from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip
from moviepy.video.tools.subtitles import SubtitlesClip
from googletrans import Translator
from langdetect import detect
import numpy as np
import codecs
import pickle
import argparse
import os
import json
import time

from moviepy.config import change_settings
change_settings({"IMAGEMAGICK_BINARY": r"C:\Program Files\ImageMagick-7.1.1-Q16-HDRI\\magick.exe"})

translator = Translator()

print("=" * 50)
print()
print('subtitle_sync ì‹¤í–‰ ì¤‘...')
startT = time.time()

# argparseë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì˜ìƒ íŒŒì¼ ì´ë¦„ì„ ì…ë ¥ìœ¼ë¡œ ë°›ìŒ
parser = argparse.ArgumentParser(description = "video Name")
parser.add_argument('--videoName', type=str, default='001')    # ë¹„ë””ì˜¤ ì´ë¦„
parser.add_argument('--language', type=str, default='ko')     # íƒ€ê²Ÿ ì–¸ì–´
args = parser.parse_args()
file_nm = args.videoName.split('.')[0]

# ìë§‰ íŒŒì¼ ê²½ë¡œ
srt_path = os.path.join(os.pardir, 'media', 'srt', f'{file_nm}.srt')
# ë™ì˜ìƒ íŒŒì¼ ê²½ë¡œ
video_path = os.path.join(os.pardir, 'media', 'videos', file_nm , 'pyavi', 'video_out.avi')
# ë™ì˜ìƒ ë¡œë“œ
video = VideoFileClip(video_path)
# ì›í•˜ëŠ” ì¶”ì¶œ ì–¸ì–´
output_lang = args.language
# ì–¼êµ´ pickle íŒŒì¼
face_score = os.path.join(os.pardir, 'media', 'videos', file_nm , 'pywork', 'scoring.pckl')

# pickle íŒŒì¼ ì½ê¸°
with open(face_score, 'rb') as f:
    faces_score = pickle.load(f)

# srt íŒŒì¼ ì½ê¸°
try:
    with codecs.open(srt_path, 'r', 'utf-8') as file:
        lines = file.readlines()
except:
    with codecs.open(srt_path, 'r', 'cp949') as file:
        lines = file.readlines()

# srtíŒŒì¼ì˜ ì‹œê°„ì„ ì´ˆë‹¨ìœ„ë¡œ ë³€ê²½í•˜ëŠ” í•¨ìˆ˜
def time_to_seconds(time_str):
    h, m, s = map(float, time_str.split(':'))
    seconds = h * 3600 + m * 60 + s
    return seconds

# ë²ˆì—­í•¨ìˆ˜
def translate(text, target='ko'):
    # do not translate if text is Korean.
    if detect(text) == target:
        return text

    try:
        result = translator.translate(text, str(target)).text
    except Exception as e:
        print(f"Translation error: {e}")
        result = text
    return result

# ìë§‰ì´ í™”ë©´ ë°–ìœ¼ë¡œ ë‚˜ê°€ëŠ” ê²ƒì„ ë°©ì§€í•˜ëŠ” í•¨ìˆ˜
def prevent_out(x, y, video, subtitles_clip):
    xx = min(max(0.02*video.w, x), 0.98*video.w - subtitles_clip.w)
    yy = min(max(0.02*video.h, y), 0.98*video.h - subtitles_clip.h)
    return xx, yy

# l2_norm í•¨ìˆ˜
def l2_norm(vector):
    squared_sum = np.sum(np.square(vector))
    norm = np.sqrt(squared_sum)
    return norm


# ìë§‰ì´ ë°°ì¹˜ëœ ë¦¬ìŠ¤íŠ¸
subtitles_clip = []
# í™”ì ê¸°ì¤€ ìë§‰ ë°°ì¹˜ ìœ„ì¹˜ ë¦¬ìŠ¤íŠ¸
po_loc = []
point_loc = []
# ìœ„ì¹˜ ì¤‘ì  ë¦¬ìŠ¤íŠ¸
pointmid_loc = []
# í™”ì tracking ë¦¬ìŠ¤íŠ¸
po_tra = []
# ì¶”ì¶œí•  pickle íŒŒì¼
out_pickle = []


k = 2
while k < len(lines):
    # ë‘ëª…ì˜ í™”ìê°€ ë§í• ë•Œ
    if lines[k+2][:2] == '--':
        line_2 = lines[k+2].replace('-','').strip() +'\n' + lines[k+3].replace('-','').strip()
        # srtíŒŒì¼ì—ì„œ ìë§‰ì˜ ì‹œì‘ì‹œê°„ê³¼ ë ì‹œê°„ì„ ë½‘ì•„ì£¼ëŠ” í•¨ìˆ˜
        start_time, end_time = lines[k + 1].strip().replace('\r','').split(' --> ')
        text = line_2.strip()
        k+=5
        #print('ddddddddd')
        
    else:
        # srtíŒŒì¼ì—ì„œ ìë§‰ì˜ ì‹œì‘ì‹œê°„ê³¼ ë ì‹œê°„ì„ ë½‘ì•„ì£¼ëŠ” í•¨ìˆ˜
        #print(k)
        start_time, end_time = lines[k + 1].strip().replace('\r','').split(' --> ')
        text = lines[k + 2].strip()
        k+=4
    
    # ìë§‰ ìƒì„± ì•ˆë˜ì—ˆì„ ê²½ìš° ì—ëŸ¬ ë°©ì§€
    if text == '':
        continue
        
    # ì›í•˜ëŠ” ì–¸ì–´ë¡œ ìë§‰ ë²ˆì—­
    text = translate(text, str(output_lang))
    
    # ìë§‰ ê¸¸ë©´ ì¤„ë°”ê¿ˆ
    if len(text) > 30:
        for i in range(30, 0, -1):
            if text[i] == ' ':
                text = text[:i]+'\n'+text[i+1:]
                break
    
    # ìë§‰ì„ ë°°ì¹˜
    if output_lang == 'ko':
        font = 'Malgun-Gothic'
    else:
        font = 'Arial-Unicode-MS'

    text_clip = (
        TextClip(text, fontsize=24, color='white', font=font)
        .set_position(("center", "bottom"))
        .set_start(start_time)
        .set_end(end_time)
    )
    
    start = int(time_to_seconds(start_time.replace(',','.'))*video.fps) # ì´ˆ * í”„ë ˆì„ (ex: 3ì´ˆë¶€ë¶„ , 25 í”„ë ˆì„ => 75)
    end = int(time_to_seconds(end_time.replace(',','.'))*video.fps)
    # ìë§‰ì´ ë‚˜ì˜¤ëŠ” ì¤‘ê°„ ì‹œê°„ ê¸°ì¤€
    mid = int((start+end)//2)
    # score ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    top_face = sorted(faces_score[mid], key=lambda x: x['ê¸°
                        norm_lst = dis_lst/norm
                        
                        # ì ì˜ lcoal energy
                        elocal = 0
                        for d in norm_lst:
                            elocal += np.exp(-10 * d**2)*d*norm
                        
                        # ì ì˜ global energy
                        eglo = (((pointmid_lst[-1][0] - x)**2 + (pointmid_lst[-1][1] - y)**2)**0.5)/norm
                        
                        # ì ì˜ layout energy
                        elay = max(x, y, video.w - x, video.h - y)/norm
                        elst.append(elocal+eglo-0.01*elay)
                
                # energy í•©ì´ ê°€ì¥ ì‘ì€ í›„ë³´ ì°¾ê¸°
                loc = 0
                for i in elst:
                    if i == min(elst):
                        break
                    loc += 1
                
                # ê·¸ í›„ë³´ì— ìë§‰ ë°°ì¹˜
                text_clip = text_clip.set_position([plist_p[loc][0], plist_p[loc][1]])
                
                # ëª¨ë“  í›„ë³´ì— bboxê°€ ê²¹ì¹  ê²½ìš° ì•„ë˜ì— ìë§‰ ë°°ì¹˜        
                if sub_change2 == [True, True, True, True, True]:
                    text_clip = text_clip.set_position((0.5*video.w - 0.5*text_clip.w, 0.95*video.h - text_clip.h))
                    point_loc.append((0.5*video.w - 0.5*text_clip.w, 0.95*video.h - text_clip.h))
                else:
                    # x1, y2 ê°’ì„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                    point_loc.append((plist_p[loc][0], plist_p[loc][1]))
        
        # ì´ì „ ìë§‰ê³¼ í˜„ì¬ ìë§‰ì˜ í™”ìê°€ ê°™ì€ë° ìë§‰ í›„ë³´ì˜ ìœ„ì¹˜ê°€ ë‹¤ë¥¸ ê²½ìš° í˜„ì¬ ìë§‰ í›„ë³´ ìœ„ì¹˜ë¡œ ì´ì „ ìë§‰ í›„ë³´ì˜ ìœ„ì¹˜ë¥¼ ë³€ê²½
        for i in range(len(po_loc)-1, -1, -1):
            if (po_loc[i] != loc) and (po_tra[i] == [d['track'] for d in top_face][0]):
                subtitles_clip[i] = subtitles_clip[i].set_position(point_loc[i+1]) # ë°”ê¾¼ë¶€ë¶„
                point_loc[i] = point_loc[i+1] # ë°”ê¾¼ë¶€ë¶„
            else:
                break
    
    # trackingì„ í†µí•´ ìë§‰ì˜ í™”ìê°€ ëˆ„êµ°ì§€ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
    if [d['track'] for d in top_face] == []:
        po_tra.append(None)
    else:
        po_tra.append([d['track'] for d in top_face][0])
    po_loc.append(loc)
    
    pointmid_loc.append((point_loc[-1][0]+0.5*text_clip.w, point_loc[-1][1]+0.5*text_clip.h))
    out_pickle.append({'start_frame': start, 'end_frame': end, 'pos': point_loc[-1], 'text': text, 'start_time': start_time, 'end_time': end_time})
    subtitles_clip.append(text_clip)

output_path = os.path.join(os.pardir, 'media', 'mid_json', f'{file_nm}.json')

with open(output_path, 'w') as f:
    out_json = { 'data' : out_pickle }
    json.dump(out_json, f, indent = 4)

endT = time.time()

print()
print('subtitle_sync ì‹¤í–‰ ì™„ë£Œ')
print(f"ğŸ•’ê±¸ë¦° ì‹œê°„ : {endT - startT:.2f} sec")
print()
