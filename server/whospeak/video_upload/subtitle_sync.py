# ë¼ì´ë¸ŒëŸ¬ë¦¬ import
from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip
from moviepy.video.tools.subtitles import SubtitlesClip
from googletrans import Translator
from langdetect import detect
import numpy as np
import codecs
import pickle
import argparse
import os
import json
import time

from moviepy.config import change_settings
change_settings({"IMAGEMAGICK_BINARY": r"C:\Program Files\ImageMagick-7.1.1-Q16-HDRI\\magick.exe"})

translator = Translator()

print("=" * 50)
print()
print('subtitle_sync ì‹¤í–‰ ì¤‘...')
startT = time.time()

# argparseë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì˜ìƒ íŒŒì¼ ì´ë¦„ì„ ì…ë ¥ìœ¼ë¡œ ë°›ìŒ
parser = argparse.ArgumentParser(description = "video Name")
parser.add_argument('--videoName', type=str, default='001')    # ë¹„ë””ì˜¤ ì´ë¦„
parser.add_argument('--language', type=str, default='ko')     # íƒ€ê²Ÿ ì–¸ì–´
args = parser.parse_args()
file_nm = args.videoName.split('.')[0]

# ìë§‰ íŒŒì¼ ê²½ë¡œ
srt_path = os.path.join(os.pardir, 'media', 'srt', f'{file_nm}.srt')
# ë™ì˜ìƒ íŒŒì¼ ê²½ë¡œ
video_path = os.path.join(os.pardir, 'media', 'videos', file_nm , 'pyavi', 'video_out.avi')
# ë™ì˜ìƒ ë¡œë“œ
video = VideoFileClip(video_path)
# ì›í•˜ëŠ” ì¶”ì¶œ ì–¸ì–´
output_lang = args.language
# ì–¼êµ´ pickle íŒŒì¼
face_score = os.path.join(os.pardir, 'media', 'videos', file_nm , 'pywork', 'scoring.pckl')

# pickle íŒŒì¼ ì½ê¸°
with open(face_score, 'rb') as f:
    faces_score = pickle.load(f)

# srt íŒŒì¼ ì½ê¸°
try:
    with codecs.open(srt_path, 'r', 'utf-8') as file:
        lines = file.readlines()
except:
    with codecs.open(srt_path, 'r', 'cp949') as file:
        lines = file.readlines()

# srtíŒŒì¼ì˜ ì‹œê°„ì„ ì´ˆë‹¨ìœ„ë¡œ ë³€ê²½í•˜ëŠ” í•¨ìˆ˜
def time_to_seconds(time_str):
    h, m, s = map(float, time_str.split(':'))
    seconds = h * 3600 + m * 60 + s
    return seconds

# ë²ˆì—­í•¨ìˆ˜
def translate(text, target='ko'):
    # do not translate if text is Korean.
    if detect(text) == target:
        return text

    try:
        result = translator.translate(text, str(target)).text
    except Exception as e:
        print(f"Translation error: {e}")
        result = text
    return result

# ìë§‰ì´ í™”ë©´ ë°–ìœ¼ë¡œ ë‚˜ê°€ëŠ” ê²ƒì„ ë°©ì§€í•˜ëŠ” í•¨ìˆ˜
def prevent_out(x, y, video, subtitles_clip):
    xx = min(max(0.02*video.w, x), 0.98*video.w - subtitles_clip.w)
    yy = min(max(0.02*video.h, y), 0.98*video.h - subtitles_clip.h)
    return xx, yy

# l2_norm í•¨ìˆ˜
def l2_norm(vector):
    squared_sum = np.sum(np.square(vector))
    norm = np.sqrt(squared_sum)
    return norm


# ìë§‰ì´ ë°°ì¹˜ëœ ë¦¬ìŠ¤íŠ¸
subtitles_clip = []
# í™”ì ê¸°ì¤€ ìë§‰ ë°°ì¹˜ ìœ„ì¹˜ ë¦¬ìŠ¤íŠ¸
po_loc = []
point_loc = []
# ìœ„ì¹˜ ì¤‘ì  ë¦¬ìŠ¤íŠ¸
pointmid_loc = []
# í™”ì tracking ë¦¬ìŠ¤íŠ¸
po_tra = []
# ì¶”ì¶œí•  pickle íŒŒì¼
out_pickle = []


k = 2
while k < len(lines):
    # ë‘ëª…ì˜ í™”ìê°€ ë§í• ë•Œ
    if lines[k+2][:2] == '--':
        line_2 = lines[k+2].replace('-','').strip() +'\n' + lines[k+3].replace('-','').strip()
        # srtíŒŒì¼ì—ì„œ ìë§‰ì˜ ì‹œì‘ì‹œê°„ê³¼ ë ì‹œê°„ì„ ë½‘ì•„ì£¼ëŠ” í•¨ìˆ˜
        start_time, end_time = lines[k + 1].strip().replace('\r','').split(' --> ')
        text = line_2.strip()
        k+=5
        #print('ddddddddd')
        
    else:
        # srtíŒŒì¼ì—ì„œ ìë§‰ì˜ ì‹œì‘ì‹œê°„ê³¼ ë ì‹œê°„ì„ ë½‘ì•„ì£¼ëŠ” í•¨ìˆ˜
        #print(k)
        start_time, end_time = lines[k + 1].strip().replace('\r','').split(' --> ')
        text = lines[k + 2].strip()
        k+=4
        # print(text)
    
    # ìë§‰ ìƒì„± ì•ˆë˜ì—ˆì„ ê²½ìš° ì—ëŸ¬ ë°©ì§€
    if text == '':
        continue
        
    # ì›í•˜ëŠ” ì–¸ì–´ë¡œ ìë§‰ ë²ˆì—­
    text = translate(text, str(output_lang))
    
    # ìë§‰ ê¸¸ë©´ ì¤„ë°”ê¿ˆ
    if len(text) > 30:
        for i in range(30, 0, -1):
            if text[i] == ' ':
                text = text[:i]+'\n'+text[i+1:]
                break
    
    # ìë§‰ì„ ë°°ì¹˜
    if output_lang == 'ko':
        font = 'Malgun-Gothic'
    else:
        font = 'Arial-Unicode-MS'

    text_clip = (
        TextClip(text, fontsize=24, color='white', font=font)
        .set_position(("center", "bottom"))
        .set_start(start_time)
        .set_end(end_time)
    )
    
    start = int(time_to_seconds(start_time.replace(',','.'))*video.fps) # ì´ˆ * í”„ë ˆì„ (ex: 3ì´ˆë¶€ë¶„ , 25 í”„ë ˆì„ => 75)
    end = int(time_to_seconds(end_time.replace(',','.'))*video.fps)
    # ìë§‰ì´ ë‚˜ì˜¤ëŠ” ì¤‘ê°„ ì‹œê°„ ê¸°ì¤€
    mid = int((start+end)//2)
    # score ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    top_face = sorted(faces_score[mid], key=lambda x: x['score'], reverse=True)
    
    loc = True
     
    # print(0.5*video.w - 0.5*text_clip.w)    
    # ìë§‰ì˜ ì¤‘ê°„ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ” bounding boxê°€ ì—†ì„ë•Œ ì•„ë˜ìª½ì— ìë§‰ ë°°ì¹˜
    if [d['bbox'] for d in top_face] == []:
        text_clip = text_clip.set_position((0.5*video.w - 0.5*text_clip.w, 0.95*video.h - text_clip.h))
        point_loc.append((0.5*video.w - 0.5*text_clip.w, 0.95*video.h - text_clip.h))
        
    # scoreê°€ 0ë³´ë‹¤ ì‘ìœ¼ë©´ í™”ìê°€ ì—†ìœ¼ë¯€ë¡œ ì•„ë˜ìª½ì— ìë§‰ ë°°ì¹˜
    elif float(top_face[0]['score']) < 0:
        text_clip = text_clip.set_position((0.5*video.w - 0.5*text_clip.w, 0.95*video.h - text_clip.h))
        point_loc.append((0.5*video.w - 0.5*text_clip.w, 0.95*video.h - text_clip.h))

    else:
        # scoreê°€ ê°€ì¥ í° bounding boxì˜ 1.6ë°° í° boxì˜ ì™¼ìª½ ì•„ë˜ ëª¨ì„œë¦¬ë¶€ë¶„ì— ìë§‰ë°°ì¹˜
        xx1, yy1, xx2, yy2 = [d['bbox'] for d in top_face][0]
        x1 = xx1 - 0.3*abs(xx2 - xx1)
        y1 = yy1 - 0.3*abs(yy2 - yy1)
        x2 = xx2 + 0.3*abs(xx2 - xx1)
        y2 = yy2 + 0.3*abs(yy2 - yy1)
        x = min(max(0.02*video.w, x1), 0.98*video.w - text_clip.w)
        y = min(max(0.02*video.h, y2), 0.98*video.h - text_clip.h)
        # ìë§‰ì´ í™”ë©´ ë°–ìœ¼ë¡œ ë‚˜ê°€ëŠ” ê²ƒì„ ë°©ì§€
        text_clip = text_clip.set_position([x, y])
        
        loc = False
            
        if len([d['bbox'] for d in top_face]) == 1:
            point_loc.append((x, y))
            pass
        
        # bboxê°€ ì—¬ëŸ¬ê°œì¼ë•Œ
        else:
            sub_change = False
            # ë§Œë“¤ì–´ì§„ ìë§‰ì´ ë‹¤ë¥¸ bboxì— ê²¹ì¹ ë•Œ
            for x_1, y_1, x_2, y_2 in [d['bbox'] for d in top_face][1:]:
                if max(0, min(x+text_clip.w, x_2) - max(x, x_1)) * max(0, min(y+text_clip.h, y_2) - max(y, y_1)) > 0:
                    sub_change = True
                    
            if sub_change == False:
                point_loc.append((x, y))
                
            # ë§Œë“¤ì–´ì§„ ìë§‰ì´ ë‹¤ë¥¸ bboxì— ê²¹ì¹ ë•Œ
            else:
                # ìë§‰ì˜ í›„ë³´ ìœ„ì¹˜ ì„ ì •
                x3, y3 = x1, y1 - text_clip.h
                x4, y4 = x2, y1 - text_clip.h
                x5, y5 = x1 - text_clip.w, y1
                x6, y6 = x2, y1
                x7, y7 = x2, y2
                
                # ìë§‰ì˜ í›„ë³´ ìœ„ì¹˜ ë¦¬ìŠ¤íŠ¸
                plist = [(x3,y3),(x4,y4),(x5,y5),(x6,y6),(x7,y7)]
                
                # ìë§‰ í›„ë³´ ìœ„ì¹˜ ë¦¬ìŠ¤íŠ¸ì— ìë§‰ ë°©ì§€ ì ìš©
                plist_p = []
                for xx_1, yy_1 in plist:
                    plist_p.append(prevent_out(xx_1, yy_1, video, text_clip))
                
                # ê° í›„ë³´ì— ìë§‰ì´ ìƒì„±ë˜ì—ˆì„ ë•Œ bboxì— ê²¹ì¹˜ëŠ” ì§€ ë¦¬ìŠ¤íŠ¸
                sub_change2 = [False, False, False, False, False]
                
                # ê²¹ì¹˜ë©´ Trueë¡œ ë³€ê²½
                for i in range(5):
                    for x_1, y_1, x_2, y_2 in [d['bbox'] for d in top_face][1:]:
                        if max(0, min(plist_p[i][0]+text_clip.w, x_2) - max(plist_p[i][0], x_1)) * \
                        max(0, min(plist_p[i][1]+text_clip.h, y_2) - max(plist_p[i][1], y_1)) > 0:
                            sub_change2[i] = True
                
                # ìë§‰ì˜ ê° í›„ë³´ì¤‘ì— bboxì— ê²¹ì¹˜ì§€ ì•ŠëŠ” í›„ë³´ì˜ ì¤‘ì  ë¦¬ìŠ¤íŠ¸ ìƒì„±
                pointmid_lst = []
                for num, (x, y) in enumerate(plist_p):
                    if sub_change2[num] == True:
                        pointmid_lst.append((True, True))
                    else:
                        pointmid_lst.append(((2*x+text_clip.w)/2, (2*y+text_clip.h)))
                
                # ìë§‰ì˜ ê° í›„ë³´ì˜ energy í•© ë¦¬ìŠ¤íŠ¸ ìƒì„±
                elst = []
                for num, (x, y) in enumerate(pointmid_lst):
                    e = 0
                    if pointmid_lst[num] == (True, True):
                        elst.append(e)
                    else:
                        dis_lst = []
                        for x_1, y_1, x_2, y_2 in [d['bbox'] for d in top_face][1:]:
                            bx_mid = (x_1+x_2)/2
                            by_mid = (y_1+y_2)/2
                            dis_lst.append(((x - bx_mid)**2 + (y - by_mid)**2)**0.5)
                            
                        # ê±°ë¦¬ ì œê³±í•© êµ¬í•˜ê¸°
                        norm = l2_norm(dis_lst)
                        
                        # ê±°ë¦¬ ì œê³±í•©ì„ ì´ìš©í•˜ì—¬ ê±°ë¦¬ë¥¼ (0,1) ë²”ìœ„ë¡œ ë°”ê¾¸ê¸°
                        norm_lst = dis_lst/norm
                        
                        # ì ì˜ lcoal energy
                        elocal = 0
                        for d in norm_lst:
                            elocal += np.exp(-10 * d**2)*d*norm
                        
                        # ì ì˜ global energy
                        eglo = (((pointmid_lst[-1][0] - x)**2 + (pointmid_lst[-1][1] - y)**2)**0.5)/norm
                        
                        # ì ì˜ layout energy
                        elay = max(x, y, video.w - x, video.h - y)/norm
                        elst.append(elocal+eglo-0.01*elay)
                
                # energy í•©ì´ ê°€ì¥ ì‘ì€ í›„ë³´ ì°¾ê¸°
                loc = 0
                for i in elst:
                    if i == min(elst):
                        break
                    loc += 1
                
                # ê·¸ í›„ë³´ì— ìë§‰ ë°°ì¹˜
                text_clip = text_clip.set_position([plist_p[loc][0], plist_p[loc][1]])
                
                # ëª¨ë“  í›„ë³´ì— bboxê°€ ê²¹ì¹  ê²½ìš° ì•„ë˜ì— ìë§‰ ë°°ì¹˜        
                if sub_change2 == [True, True, True, True, True]:
                    text_clip = text_clip.set_position((0.5*video.w - 0.5*text_clip.w, 0.95*video.h - text_clip.h))
                    point_loc.append((0.5*video.w - 0.5*text_clip.w, 0.95*video.h - text_clip.h))
                else:
                    # x1, y2 ê°’ì„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                    point_loc.append((plist_p[loc][0], plist_p[loc][1]))
        
        # ì´ì „ ìë§‰ê³¼ í˜„ì¬ ìë§‰ì˜ í™”ìê°€ ê°™ì€ë° ìë§‰ í›„ë³´ì˜ ìœ„ì¹˜ê°€ ë‹¤ë¥¸ ê²½ìš° í˜„ì¬ ìë§‰ í›„ë³´ ìœ„ì¹˜ë¡œ ì´ì „ ìë§‰ í›„ë³´ì˜ ìœ„ì¹˜ë¥¼ ë³€ê²½
        for i in range(len(po_loc)-1, -1, -1):
            if (po_loc[i] != loc) and (po_tra[i] == [d['track'] for d in top_face][0]):
                subtitles_clip[i] = subtitles_clip[i].set_position(point_loc[i+1]) # ë°”ê¾¼ë¶€ë¶„
                point_loc[i] = point_loc[i+1] # ë°”ê¾¼ë¶€ë¶„
            else:
                break
    
    # trackingì„ í†µí•´ ìë§‰ì˜ í™”ìê°€ ëˆ„êµ°ì§€ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
    if [d['track'] for d in top_face] == []:
        po_tra.append(None)
    else:
        po_tra.append([d['track'] for d in top_face][0])
    po_loc.append(loc)
    
    pointmid_loc.append((point_loc[-1][0]+0.5*text_clip.w, point_loc[-1][1]+0.5*text_clip.h))
    out_pickle.append({'start_frame': start, 'end_frame': end, 'pos': point_loc[-1], 'text': text, 'start_time': start_time, 'end_time': end_time})
    subtitles_clip.append(text_clip)

output_path = os.path.join(os.pardir, 'media', 'mid_json', f'{file_nm}.json')

with open(output_path, 'w') as f:
    out_json = { 'data' : out_pickle }
    json.dump(out_json, f, indent = 4)

endT = time.time()

print()
print('subtitle_sync ì‹¤í–‰ ì™„ë£Œ')
print(f"ğŸ•’ê±¸ë¦° ì‹œê°„ : {endT - startT:.2f} sec")
print()
